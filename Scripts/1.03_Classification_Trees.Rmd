---
title: "1.03_Classification_Trees"
author: "Andrew Davis"
date: "1/20/2020"
output: html_document
---

# Tree-based models
Interpretability + ease-of-use + accuracy
Make decisions + numeric predictions

Decision tree terminology: nodes
Root node – internal nodes – terminal nodes

## Training decisions trees in R using the rpart package
rpart package:
Recursive Partitioning and Regression and survival trees. 

```{r}
# Install cran packages
list.of.packages <- c("rpart","rpart.plot")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(rpart)
library(rpart.plot)
```




```{r}
creditsub<-read.csv("../Input/credit.csv")

str(creditsub)

Credit_model <- rpart(formula = default ~ ., data = creditsub, method = "class")
#display the results:
rpart.plot(x=Credit_model, yesno=2, type = 0, extra = 0)
```

## Intro to classification trees

Advantages:
One of the biggest advantages - simple to understand, interpret, and visualize
Require no normalization for numerical features
Can handle both numerical and categorical features (inputs) natively
Can handle missing data elegantly – do you go down the train right or left (randomly)?
Requires little data preparation
Can model non-linearity in the data
Can be trained quickly on data sets

Disadvantages:
Large trees can be hard to interpret
Trees have high variance, which causes model performance to be poor
Trees overfit easily

## Overview of the modeling process:
Train/test split
Example: Training on 80% or testing on 20% 

### How to do it in R:
```{r}
# Total number of rows in the credit data frame
n <- nrow(creditsub)

# Number of rows for the training set (80% of the dataset)
n_train <- round(0.8 * n) 

# Create a vector of indices which is an 80% random sample
set.seed(123)
train_indices <- sample(1:n, n_train)
# Subset the credit data frame to training indices only
credit_train <- creditsub[train_indices, ]  
  
# Exclude the training indices to create the test set
credit_test <- creditsub[-train_indices, ]  

# Train the model (to predict 'default')
credit_model <- rpart(formula = default ~., 
                      data = credit_train, 
                      method = "class")

# Look at the model output                      
print(credit_model)
```

## Evaluate model performance:
Predict(model, test_dataset, type= _ _ _)

Evaluation metrics for binary classification 
Accuracy
Confusion matrix
Log-loss
AUC

Accuracy = (n of correct predictions)/(n of total data points)
Confusion matrix shows a more detailed break down (e.g. type I error (false positive) vs. type II error (false negative))

### package for generating confusion matrix
```{r}
install.packages('caret')
install.packages('e1071')

library(caret)
library(e1071)

# Generate predicted classes using the model object
class_prediction <- predict(object = credit_model,  
                        newdata = credit_test,   
                        type = "class")  
                            
# Calculate the confusion matrix for the test set
confusionMatrix(data = class_prediction,       
                reference = credit_test$default)  
```

## Use of splitting criterion in trees:

Comparing models with different splitting criterion.


We want to minimize the impurity measure – Gini Index
The lower the Gini index, the higher the purity index. 

# Comparing two models:
```{r}
### Train a gini-based model
credit_model1 <- rpart(formula = default ~ ., 
                       data = credit_train, 
                       method = "class",
                       parms = list(split = "gini"))

### Train an information-based model
credit_model2 <- rpart(formula = default ~ ., 
                       data = credit_train, 
                       method = "class",
                       parms = list(split = "information"))

### Generate predictions on the validation set using the gini model
pred1 <- predict(object = credit_model1, 
             newdata = credit_test,
             type = "class")    

### Generate predictions on the validation set using the information model
pred2 <- predict(object = credit_model2, 
             newdata = credit_test,
             type = "class")

### Load ModelMetrics to calculate classification error
library(ModelMetrics)

### Compare classification errors
ce(actual = credit_test$default, 
   predicted = pred1)
ce(actual = credit_test$default, 
   predicted = pred2)  
```